{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNet Model on RGB 5G Dataset\n",
    "\n",
    "The dataset consists of 5 classes:\n",
    "\n",
    "![Image.png]('F:\\FCV\\Image.png')\n",
    "\n",
    "Training Accuracy : 68.87%\n",
    "Validation Accuracy : 28.4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries as shown below\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = r'F:\\\\FCV\\\\data\\\\Train\\\\'\n",
    "valid_path = r'F:\\\\FCV\\\\data\\\\Test\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 8s 0us/step\n",
      "17235968/17225924 [==============================] - 8s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Import the mobilenet library as shown below and add preprocessing layer to the front of MobileNet\n",
    "# Here we will be using imagenet weights\n",
    "\n",
    "mobilenet = MobileNet(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't train existing weights\n",
    "for layer in mobilenet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for getting number of output classes\n",
    "folders = glob(r'F:\\\\FCV\\\\data\\\\Train\\*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = Flatten()(mobilenet.output)\n",
    "prediction = Dense(len(folders), activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model object\n",
    "model_mobilenet_RGB = Model(inputs=mobilenet.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model_mobilenet_RGB.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Image Data Generator to import the images from the dataset\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you provide the same target size as initialied for the image size\n",
    "training_set = train_datagen.flow_from_directory(train_path,\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(valid_path,\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 141s 3s/step - loss: 6.2038 - accuracy: 0.2720 - val_loss: 2.9490 - val_accuracy: 0.3560\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 119s 3s/step - loss: 3.3124 - accuracy: 0.3820 - val_loss: 3.5211 - val_accuracy: 0.3080\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 119s 3s/step - loss: 2.1490 - accuracy: 0.4807 - val_loss: 2.9193 - val_accuracy: 0.4120\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 121s 3s/step - loss: 2.0135 - accuracy: 0.5407 - val_loss: 3.1280 - val_accuracy: 0.3520\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 117s 2s/step - loss: 1.9424 - accuracy: 0.5587 - val_loss: 3.9676 - val_accuracy: 0.2960\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 117s 2s/step - loss: 1.7652 - accuracy: 0.6293 - val_loss: 4.1388 - val_accuracy: 0.3240\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 117s 2s/step - loss: 1.5653 - accuracy: 0.6573 - val_loss: 4.9396 - val_accuracy: 0.3280\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 120s 3s/step - loss: 1.3755 - accuracy: 0.6887 - val_loss: 3.8344 - val_accuracy: 0.3380\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 124s 3s/step - loss: 1.2653 - accuracy: 0.7173 - val_loss: 4.7919 - val_accuracy: 0.3280\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 137s 3s/step - loss: 1.3943 - accuracy: 0.6887 - val_loss: 5.2934 - val_accuracy: 0.2840\n",
      "model saved to Disk.\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "# Run the cell. It will take some time to execute\n",
    "history_mobilenet_RGB = model_mobilenet_RGB.fit(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=10,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")    \n",
    "\n",
    "model_mobilenet_RGB.save('mobilenet_RGB_model.h5')\n",
    "print(\"model saved to Disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the loss\n",
    "plt.plot(history_mobilenet_RGB.history['loss'], label='train loss')\n",
    "plt.plot(history_mobilenet_RGB.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(history_mobilenet_RGB.history['accuracy'], label='val acc')\n",
    "plt.plot(history_mobilenet_RGB.history['val_accuracy'], label='train acc')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded.\n"
     ]
    }
   ],
   "source": [
    "# dirname = os.path.join(os.path.dirname(__file__))\n",
    "model_mobilenet_new_RGB = load_model('mobilenet_RGB_model.h5')\n",
    "print(\"model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = ImageDataGenerator(rescale = 1./255)\n",
    "test_data_generator = test_generator.flow_from_directory(\n",
    "    valid_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=False)\n",
    "test_steps_per_epoch = np.math.ceil(test_data_generator.samples / test_data_generator.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_mobilenet_new_RGB.predict(test_data_generator, steps=test_steps_per_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "[4 2 2 2 4 4 1 3 1 4 1 1 4 2 0 1 1 4 3 4 2 3 4 4 2 4 4 1 4 1 4 2 3 1 1 4 1\n",
      " 4 4 1 2 2 1 1 2 4 1 1 1 1 4 4 1 0 0 1 4 4 4 2 1 4 1 2 4 4 2 2 1 4 2 4 1 0\n",
      " 3 4 4 2 4 4 1 4 2 2 1 3 1 4 1 1 0 1 4 3 1 1 2 3 2 1 4 4 1 1 4 4 1 4 4 1 1\n",
      " 4 1 1 4 4 1 4 4 4 1 1 4 1 4 1 1 1 1 4 4 1 4 1 1 4 4 4 2 2 1 1 1 4 3 1 1 1\n",
      " 3 4 4 4 4 4 1 4 3 4 1 4 4 4 3 1 1 4 4 1 4 1 4 1 3 4 1 4 1 1 1 4 3 4 4 3 4\n",
      " 1 4 4 4 4 1 1 4 1 4 4 1 4 4 4 1 1 1 2 4 3 1 4 0 0 1 0 0 1 1 4 4 2 0 1 4 1\n",
      " 2 4 3 1 3 4 1 4 0 4 2 2 3 3 2 1 2 2 2 1 2 2 2 3 4 2 2 2 4 1 0 2 4 1 4 2 1\n",
      " 2 2 4 0 4 1 2 4 2 4 2 4 1 1 1 4 2 2 2 4 1 4 0 2 4 2 4 4 0 2 1 1 0 1 1 2 1\n",
      " 4 4 4 4 4 4 4 1 1 3 4 1 4 1 3 2 3 4 4 1 1 1 1 1 4 1 4 1 4 4 1 4 4 4 4 4 4\n",
      " 4 1 4 3 4 4 4 1 1 3 4 1 4 4 4 4 4 4 4 4 4 1 3 1 1 1 4 4 4 1 1 1 4 1 4 4 1\n",
      " 4 1 1 1 2 4 4 4 4 4 3 3 4 4 1 4 1 1 4 1 4 4 3 4 4 4 4 1 4 1 4 4 3 1 2 1 4\n",
      " 4 1 4 1 4 1 4 4 4 4 4 1 4 4 3 4 1 4 4 4 1 4 4 1 4 4 4 4 3 1 1 1 4 4 4 4 4\n",
      " 1 4 3 4 4 1 4 4 4 1 3 1 4 4 1 3 4 1 1 1 4 4 4 1 1 1 1 4 4 4 1 1 4 1 4 1 4\n",
      " 4 4 1 4 4 4 4 4 4 1 4 1 4 4 3 1 4 4 1]\n"
     ]
    }
   ],
   "source": [
    "# Get most likely class\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(test_data_generator.classes)\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = test_data_generator.classes\n",
    "class_labels = list(test_data_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       16QAM       0.31      0.05      0.09       100\n",
      "       32QAM       0.24      0.40      0.30       100\n",
      "        4QAM       0.54      0.29      0.38       100\n",
      "       64QAM       0.24      0.09      0.13       100\n",
      "        8QAM       0.26      0.59      0.36       100\n",
      "\n",
      "    accuracy                           0.28       500\n",
      "   macro avg       0.32      0.28      0.25       500\n",
      "weighted avg       0.32      0.28      0.25       500\n",
      "\n",
      "[[ 5 33 20  8 34]\n",
      " [ 0 40  2  7 51]\n",
      " [11 26 29  6 28]\n",
      " [ 0 34  2  9 55]\n",
      " [ 0 33  1  7 59]]\n",
      "0.284\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "cmat = confusion_matrix(true_classes, predicted_classes)\n",
    "acc = accuracy_score(true_classes, predicted_classes)\n",
    "print(report) \n",
    "print(cmat)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mtx = confusion_matrix(true_classes, predicted_classes) \n",
    "# plot the confusion matrix\n",
    "f,ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "ax.set_xticklabels(['4QAM_RGB', '8QAM_RGB', '16QAM_RGB', '32QAM_RGB', '64QAM_RGB'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "ax.set_yticklabels(['4QAM_RGB', '8QAM_RGB', '16QAM_RGB', '32QAM_RGB', '64QAM_RGB'])\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
